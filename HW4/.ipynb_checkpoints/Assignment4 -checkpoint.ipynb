{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 252A Computer Vision I Fall 2018 - Assignment 4\n",
    "\n",
    "### Instructor: David Kriegman\n",
    "### Assignment Published On: Tuesday, November 27, 2018\n",
    "### Due On: Friday, December 7, 2018 11:59 pm\n",
    "\n",
    "## Instructions\n",
    "* Review the academic integrity and collaboration policies on the course website.\n",
    "* This assignment must be completed individually.\n",
    "* Programming aspects of this assignment must be completed using Python in this notebook.\n",
    "* If you want to modify the skeleton code, you can do so. This has been provided just to provide you with a framework for the solution.\n",
    "* You may use python packages for basic linear algebra (you can use numpy or scipy for basic operations), but you may not use packages that directly solve the problem.\n",
    "* If you are unsure about using a specific package or function, then ask the instructor and teaching assistants for clarification.\n",
    "* You must submit this notebook exported as a pdf. You must also submit this notebook as .ipynb file.\n",
    "* You must submit both files (.pdf and .ipynb) on Gradescope. You must mark each problem on Gradescope in the pdf.\n",
    "* **Late policy** - 10% per day late penalty after due date up to 3 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Optical Flow [10 pts]\n",
    "\n",
    "In this problem, the single scale Lucas-Kanade method for estimating optical flow will be implemented, and the data needed for this problem can be found in the folder 'optical_flow_images'.\n",
    "\n",
    "An example optical flow output is shown below - this is not a solution, just an example output.\n",
    "\n",
    "![title](optical_flow_images/sample_optical_flow_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Lucas-Kanade implementation [5 pts]\n",
    "\n",
    "Implement the Lucas-Kanade method for estimating optical flow. The function 'LucasKanade' needs to be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d as conv2\n",
    "\n",
    "def grayscale(img):\n",
    "    '''\n",
    "    Converts RGB image to Grayscale\n",
    "    '''\n",
    "    gray=np.zeros((img.shape[0],img.shape[1]))\n",
    "    gray=img[:,:,0]*0.2989+img[:,:,1]*0.5870+img[:,:,2]*0.1140\n",
    "    return gray\n",
    "\n",
    "def plot_optical_flow(img,U,V):\n",
    "    '''\n",
    "    Plots optical flow given U,V and one of the images\n",
    "    '''\n",
    "    \n",
    "    # Change t if required, affects the number of arrows\n",
    "    # t should be between 1 and min(U.shape[0],U.shape[1])\n",
    "    t=10 \n",
    "    \n",
    "    # Subsample U and V to get visually pleasing output\n",
    "    U1 = U[::t,::t]\n",
    "    V1 = V[::t,::t]\n",
    "    \n",
    "    # Create meshgrid of subsampled coordinates\n",
    "    r, c = img.shape[0],img.shape[1]\n",
    "    cols,rows = np.meshgrid(np.linspace(0,c-1,c), np.linspace(0,r-1,r))\n",
    "    cols = cols[::t,::t]\n",
    "    rows = rows[::t,::t]\n",
    "    \n",
    "    # Plot optical flow\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img)\n",
    "    plt.quiver(cols,rows,U1,V1)\n",
    "    plt.show()\n",
    "\n",
    "images=[]\n",
    "for i in range(1,5):\n",
    "    images.append(plt.imread('optical_flow_images/im'+str(i)+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LucasKanade(im1,im2,window):\n",
    "    '''\n",
    "    Inputs: the two images and window size\n",
    "    Return U,V\n",
    "    '''\n",
    "    U = np.zeros(im1.shape)\n",
    "    V = np.zeros(im1.shape)\n",
    "    \n",
    "    '''\n",
    "    Your code here\n",
    "    '''\n",
    "    \n",
    "    return U,V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Window size [2 pts]\n",
    "\n",
    "Plot optical flow for the pair of images im1 and im2 for at least 3 different window sizes which leads to observable difference in the results. Comment on the effect of window size on results and justify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example code, change as required\n",
    "window=5\n",
    "U,V=LucasKanade(grayscale(images[0]),grayscale(images[1]),window)\n",
    "plot_optical_flow(images[0],U,V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: All pairs [3 pts]\n",
    "\n",
    "Find optical flow for the pairs (im1,im2), (im1,im3), (im1,im4) using a good window size. Does the optical flow result seem consistent with visual inspection? Comment on the type of motion indicated by results and visual inspection and explain why they might be consistent or inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Machine Learning [12 pts]\n",
    "\n",
    "In this problem, you will implement several machine learning solutions for computer vision problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Initial setup [1 pts]\n",
    "\n",
    "Follow the directions on https://www.tensorflow.org/install/ to install Tensorflow on your computer.\n",
    "If you are using the Anaconda distribution for python, you can check out https://www.anaconda.com/blog/developer-blog/tensorflow-in-anaconda/.\n",
    "\n",
    "Note: You will not need GPU support for this assignment so don't worry if you don't have one. Furthermore, installing with GPU support is often more difficult to configure so it is suggested that you install the CPU only version.\n",
    "\n",
    "Run the tensorflow hello world snippet below to verify your instalation.\n",
    "\n",
    "Download the MNIST data from http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "Download the 4 zipped files, extract them into one folder, and change the variable 'path' in the code below. (Code taken from https://gist.github.com/akesling/5358964 )\n",
    "\n",
    "Plot one random example image corresponding to each label from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "# Change path as required\n",
    "path = \"./mnist_data/\"\n",
    "\n",
    "def read(dataset = \"training\", datatype='images'):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "    \n",
    "    if(datatype=='images'):\n",
    "        get_data = lambda idx: img[idx]\n",
    "    elif(datatype=='labels'):\n",
    "        get_data = lambda idx: lbl[idx]\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_data(i)\n",
    "        \n",
    "trainData=np.array(list(read('training','images')))\n",
    "trainLabels=np.array(list(read('training','labels')))\n",
    "testData=np.array(list(read('testing','images')))\n",
    "testLabels=np.array(list(read('testing','labels')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a generator for batches of data\n",
    "# yields data (batchsize, 3, 32, 32) and labels (batchsize)\n",
    "# if shuffle, it will load batches in a random order\n",
    "def DataBatch(data, label, batchsize, shuffle=True):\n",
    "    n = data.shape[0]\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(n)\n",
    "    else:\n",
    "        index = np.arange(n)\n",
    "    for i in range(int(np.ceil(n/batchsize))):\n",
    "        inds = index[i*batchsize : min(n,(i+1)*batchsize)]\n",
    "        yield data[inds], label[inds]\n",
    "\n",
    "# tests the accuracy of a classifier\n",
    "def test(testData, testLabels, classifier):\n",
    "    batchsize=50\n",
    "    correct=0.\n",
    "    for data,label in DataBatch(testData,testLabels,batchsize,shuffle=False):\n",
    "        prediction = classifier(data)\n",
    "        correct += np.sum(prediction==label)\n",
    "    return correct/testData.shape[0]*100\n",
    "\n",
    "# a sample classifier\n",
    "# given an input it outputs a random class\n",
    "class RandomClassifier():\n",
    "    def __init__(self, classes=10):\n",
    "        self.classes=classes\n",
    "    def __call__(self, x):\n",
    "        return np.random.randint(self.classes, size=x.shape[0])\n",
    "\n",
    "randomClassifier = RandomClassifier()\n",
    "print('Random classifier accuracy: %f' % \n",
    "      test(testData, testLabels, randomClassifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Confusion Matrix [2 pts]\n",
    "Here you will implement a function that computes the confusion matrix for a classifier.\n",
    "The matrix (M) should be nxn where n is the number of classes.\n",
    "Entry M[i,j] should contain the fraction of images of class i that was classified as class j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the tqdm module to visualize run time is suggested\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# It would be a good idea to return the accuracy, along with the confusion \n",
    "# matrix, since both can be calculated in one iteration over test data, to \n",
    "# save time\n",
    "def Confusion(testData, testLabels, classifier):\n",
    "    '''\n",
    "    Your code here\n",
    "    '''\n",
    "\n",
    "def VisualizeConfusion(M):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.imshow(M)\n",
    "    plt.show()\n",
    "    print(np.round(M,2))\n",
    "\n",
    "M = Confusion(testData, testLabels, randomClassifier)\n",
    "VisualizeConfusion(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: K-Nearest Neighbors (KNN) [4 pts]\n",
    "\n",
    "* Here you will implement a simple knn classifier. The distance metric is Euclidean in pixel space. k refers to the number of neighbors involved in voting on the class, and should be 3. You are allowed to use sklearn.neighbors.KNeighborsClassifier.\n",
    "* Display confusion matrix and accuracy for your KNN classifier trained on the entire train set. (should be ~97 %)\n",
    "* After evaluating the classifier on the testset, based on the confusion matrix, mention the number that the number '4' is most often predicted to be, other than '4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "class KNNClassifer():\n",
    "    def __init__(self, k=3):\n",
    "        # k is the number of neighbors involved in voting\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # this method should take a batch of images\n",
    "        # and return a batch of predictions\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "\n",
    "\n",
    "# test your classifier with only the first 100 training examples (use this\n",
    "# while debugging)\n",
    "# note you should get ~ 65 % accuracy\n",
    "knnClassiferX = KNNClassifer()\n",
    "knnClassiferX.train(trainData[:100], trainLabels[:100])\n",
    "print ('KNN classifier accuracy: %f'%test(testData, testLabels, knnClassiferX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test your classifier with all the training examples (This may take a while)\n",
    "knnClassifer = KNNClassifer()\n",
    "knnClassifer.train(trainData, trainLabels)\n",
    "\n",
    "# display confusion matrix for your KNN classifier with all the training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Principal Component Analysis (PCA) K-Nearest Neighbors (KNN) [5 pts]\n",
    "Here you will implement a simple KNN classifer in PCA space (for k=3 and 25 principal components).\n",
    "You should implement PCA yourself using svd (you may not use sklearn.decomposition.PCA\n",
    "or any other package that directly implements PCA transformations\n",
    "\n",
    "Is the testing time for PCA KNN classifier more or less than that for KNN classifier? Comment on why it differs if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PCAKNNClassifer():\n",
    "    def __init__(self, components=25, k=3):\n",
    "        # components = number of principal components\n",
    "        # k is the number of neighbors involved in voting\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # this method should take a batch of images\n",
    "        # and return a batch of predictions\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "\n",
    "\n",
    "# test your classifier with only the first 100 training examples (use this\n",
    "# while debugging)\n",
    "pcaknnClassiferX = PCAKNNClassifer()\n",
    "pcaknnClassiferX.train(trainData[:100], trainLabels[:100])\n",
    "print ('KNN classifier accuracy: %f'%test(testData, testLabels, knnClassiferX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test your classifier with all the training examples (This may take a while)\n",
    "pcaknnClassifer = PCAKNNClassifer()\n",
    "pcaknnClassifer.train(trainData, trainLabels)\n",
    "\n",
    "# display confusion matrix for your PCA KNN classifier with all the training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Deep learning [12 pts]\n",
    "Below is some helper code to train your deep networks. You can look at https://www.tensorflow.org/get_started/mnist/beginners for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base class for your Tensorflow networks. It implements the training loop\n",
    "# (train) and prediction(__call__)  for you.\n",
    "# You will need to implement the __init__ function to define the networks\n",
    "# structures in the following problems.\n",
    "\n",
    "class TFClassifier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, trainData, trainLabels, epochs=1, batchsize=50):\n",
    "        self.prediction = tf.argmax(self.y,1)\n",
    "        self.cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y_, logits=self.y))\n",
    "        self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.cross_entropy)\n",
    "        self.correct_prediction = tf.equal(self.prediction, self.y_)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for i, (data,label) in enumerate(DataBatch(trainData, trainLabels, batchsize, shuffle=True)):\n",
    "                data=np.expand_dims(data,-1)\n",
    "                _, acc = self.sess.run([self.train_step, self.accuracy], feed_dict={self.x: data, self.y_: label})\n",
    "                \n",
    "            print ('Epoch:%d Accuracy: %f'%(epoch+1, test(testData, testLabels, self)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        return self.sess.run(self.prediction, feed_dict={self.x: np.expand_dims(x,-1)})\n",
    "    \n",
    "    def get_first_layer_weights(self):\n",
    "        return self.sess.run(self.weights[0])\n",
    "\n",
    "# helper function to get weight variable\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# helper function to get bias variable\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# example linear classifier\n",
    "class LinearClassifier(TFClassifier):\n",
    "    def __init__(self, classes=10):\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None,28,28,1]) # input batch of images\n",
    "        self.y_ = tf.placeholder(tf.int64, shape=[None]) # input labels\n",
    "\n",
    "        # model variables\n",
    "        self.weights = [weight_variable([28*28,classes])]\n",
    "        self.biases = [bias_variable([classes])]\n",
    "\n",
    "        # linear operation\n",
    "        self.y = tf.matmul(tf.reshape(self.x,(-1,28*28*1)),self.weights[0]) + self.biases[0]\n",
    "        \n",
    "\n",
    "# test the example linear classifier (note you should get around 90% accuracy\n",
    "# for 10 epochs and batchsize 50)\n",
    "linearClassifier = LinearClassifier()\n",
    "linearClassifier.train(trainData, trainLabels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Single Layer Perceptron [2 pts]\n",
    "The simple linear classifier implemented in the cell already performs quite well. Plot the filter weights corresponding to each output class (weights, not biases) as images. (Normalize weights to lie between 0 and 1 and use color maps like 'inferno' or 'plasma' for good results). Comment on what the weights look like and why that may be so.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Multi Layer Perceptron (MLP) [5 pts]\n",
    "Here you will implement an MLP. The MLP shoud consist of 2 layers (matrix multiplication and bias offset) that map to the following feature dimensions:\n",
    "\n",
    "* 28x28 -> hidden (100)\n",
    "* hidden -> classes\n",
    "\n",
    "* The hidden layer should be followed with a ReLU nonlinearity. The final layer should not have a nonlinearity applied as we desire the raw logits output.\n",
    "* The final output of the computation graph should be stored in self.y as that will be used in the training.\n",
    "\n",
    "Display the confusion matrix and accuracy after training. Note: You should get ~ 97 % accuracy for 10 epochs and batch size 50.\n",
    "\n",
    "Plot the filter weights corresponding to the mapping from the inputs to the first 10 hidden layer outputs (out of 100). Do the weights look similar to the weights plotted in the previous problem? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLPClassifer(TFClassifier):\n",
    "    def __init__(self, classes=10, hidden=100):\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "\n",
    "mlpClassifer = MLPClassifer()\n",
    "mlpClassifer.train(trainData, trainLabels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Convolutional Neural Network (CNN) [5 pts]\n",
    "Here you will implement a CNN with the following architecture:\n",
    "\n",
    "* n=5\n",
    "* ReLU( Conv(kernel_size=4x4, stride=2, output_features=n) )\n",
    "* ReLU( Conv(kernel_size=4x4, stride=2, output_features=n*2) )\n",
    "* ReLU( Conv(kernel_size=4x4, stride=2, output_features=n*4) )\n",
    "* Linear(output_features=classes)\n",
    "\n",
    "Display the confusion matrix and accuracy after training. You should get around ~ 98 % accuracy for 10 epochs and batch size 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, stride=2):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "class CNNClassifer(TFClassifier):\n",
    "    def __init__(self, classes=10, n=5):\n",
    "        '''\n",
    "        your code here\n",
    "        '''\n",
    "\n",
    "cnnClassifer = CNNClassifer()\n",
    "cnnClassifer.train(trainData, trainLabels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that the MLP/ConvNet approaches lead to an accuracy a little higher than the K-NN approach. \n",
    "* In general, Neural net approaches lead to significant increase in accuracy, but in this case since the problem is not too hard, the increase in accuracy is not very high.\n",
    "* However, this is still quite significant considering the fact that the ConvNets we've used are relatively simple while the accuracy achieved using K-NN is with a search over 60,000 training images for every test image.\n",
    "* You can look at the performance of various machine learning methods on this problem at http://yann.lecun.com/exdb/mnist/\n",
    "* You can learn more about neural nets/ tensorflow at https://www.tensorflow.org/tutorials/\n",
    "* You can play with a demo of neural network created by Daniel Smilkov and Shan Carter at https://playground.tensorflow.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
